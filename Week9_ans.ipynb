{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /Users/jina/Desktop/pyWorkspace/langchain_env\n",
      "OPENAI_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 현재 작업 디렉토리 확인\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 현재 디렉토리의 .env 파일 경로 지정\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(override=True)  # override=True를 사용하여 기존 값을 덮어씁니다\n",
    "\n",
    "# 환경변수 확인\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(\"OPENAI_API_KEY:\", api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 텍스트 분할기(Text Splitter) 임포트\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# - 긴 문서를 작은 청크로 재귀적으로 분할\n",
    "# - chunk_size: 각 청크의 최대 문자 수\n",
    "# - chunk_overlap: 청크 간 중복되는 문자 수\n",
    "# - 문서의 의미적 맥락을 유지하면서 분할하려고 시도\n",
    "\n",
    "# 2. 각종 문서 로더(Document Loader) 임포트\n",
    "from langchain_community.document_loaders import (\n",
    "    PDFMinerLoader,      # PDF 파일용 로더\n",
    "    ArxivLoader,         # arXiv 논문 로더\n",
    ")\n",
    "# - PDFMinerLoader: Python 네이티브 PDF 파서, 텍스트 레이아웃 보존에 강점\n",
    "# - ArxivLoader: arXiv에서 논문 정보와 본문을 직접 가져옴\n",
    "# - WebBaseLoader: URL에서 웹 페이지 내용을 가져옴\n",
    "\n",
    "# 3. 벡터 저장소(Vector Store) 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# - Facebook AI의 벡터 유사도 검색 라이브러리\n",
    "# - 고차원 벡터의 효율적인 유사도 검색 지원\n",
    "# - 메모리 기반으로 동작하여 빠른 검색 가능\n",
    "\n",
    "# 4. 출력 파서(Output Parser) 임포트\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# - LLM의 출력을 문자열로 변환\n",
    "# - 구조화된 출력을 처리할 때 사용\n",
    "\n",
    "# 5. 실행 가능한 컴포넌트(Runnable) 임포트\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# - 입력을 수정 없이 다음 단계로 전달\n",
    "# - 체인 구성에서 중간 데이터 전달 역할\n",
    "\n",
    "# 6. 프롬프트 템플릿(Prompt Template) 임포트\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# - 재사용 가능한 프롬프트 템플릿 생성\n",
    "# - 변수를 포함한 동적 프롬프트 생성 가능\n",
    "\n",
    "# 7. OpenAI 컴포넌트 임포트\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# ChatOpenAI: \n",
    "# - OpenAI의 GPT 모델을 사용하는 인터페이스\n",
    "# - 대화형 AI 응답 생성\n",
    "# OpenAIEmbeddings:\n",
    "# - 텍스트를 벡터로 변환하는 임베딩 모델\n",
    "# - 텍스트의 의미적 검색을 위한 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 1\n",
      "\n",
      "문서 메타데이터: {'source': 'Ch03.pdf'}\n",
      "\n",
      "문서 내용 샘플 (처음 300자): Chapter 3\n",
      "The Role of IT Governance\n",
      "\n",
      "The following exam domain is partially covered in this chapter: Domain 2--Governance and Management of IT\n",
      "\n",
      "This chapter covers the following topics:\n",
      "- The IT Steering Committee\n",
      "- Corporate Structure\n",
      "- IT Governance Frameworks\n",
      "- Enterprise Risk Management\n",
      "- Policy\n"
     ]
    }
   ],
   "source": [
    "# 1. PDF 문서 로드\n",
    "def load_pdf_document(file_path):\n",
    "    \"\"\"PDF 파일을 로드하고 기본 정보를 출력하는 함수\"\"\"\n",
    "    loader = PDFMinerLoader(file_path)  # PDF 파일 경로 지정\n",
    "    documents = loader.load()\n",
    "    print(f\"로드된 문서 수: {len(documents)}\")  # 페이지 수 확인\n",
    "    print(\"\\n문서 메타데이터:\", documents[0].metadata)\n",
    "    print(\"\\n문서 내용 샘플 (처음 300자):\", documents[0].page_content[:300])\n",
    "    return documents\n",
    "\n",
    "pdf_document = load_pdf_document(\"Ch03.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 173\n"
     ]
    }
   ],
   "source": [
    "# 2. 문서 분할\n",
    "def split_documents(documents):\n",
    "    \"\"\"문서를 청크로 분할하는 함수\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, # 각 청크의 최대 문자 수\n",
    "        chunk_overlap=200,# 청크 간 중복되는 문자 수 (문맥 유지를 위해)\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"생성된 청크 수: {len(splits)}\")\n",
    "    return splits\n",
    "\n",
    "splits = split_documents(pdf_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RAG 시스템 구축\n",
    "def build_rag_system(splits):\n",
    "    \"\"\"RAG 시스템을 구축하는 함수\"\"\"\n",
    "\n",
    "    # 벡터 저장소 생성\n",
    "    embeddings = OpenAIEmbeddings()  # OpenAI 임베딩 모델 초기화\n",
    "    vectorstore = FAISS.from_documents( # 문서 벡터들을 효율적으로 저장하고 검색할 수 있는 벡터 데이터베이스 생성\n",
    "        documents=splits, # 이전 단계에서 분할된 문서 조각들\n",
    "        embedding=embeddings # OpenAI 임베딩 모델을 사용하여 각 문서 조각을 벡터로 변환\n",
    "    )\n",
    "\n",
    "    # 검색기(Retriever) 설정\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"k\": 3}  # 검색할 문서 수\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 프롬프트 템플릿 설정\n",
    "    template = \"\"\"주어진 문서 내용을 바탕으로 질문에 답변해주세요.\n",
    "    문서에 없는 내용이면 \"주어진 문서에서 해당 내용을 찾을 수 없습니다.\"라고 답변해주세요.\n",
    "    \n",
    "    문서 내용:\n",
    "    {context}\n",
    "    \n",
    "    질문:\n",
    "    {question}\n",
    "    \n",
    "    답변:\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    # LLM 설정\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # 응답의 창의성 수준 (0: 일관된 응답)\n",
    "        model_name=\"gpt-4o\"  # 사용할 모델\n",
    "    )\n",
    "    \n",
    "    # RAG 체인 구성\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return chain\n",
    "\n",
    "chain = build_rag_system(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 질의-응답 함수\n",
    "def ask_document(chain, question):\n",
    "    \"\"\"문서에 대해 질문하고 답변을 받는 함수\"\"\"\n",
    "    response = chain.invoke(question)\n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(f\"답변: {response}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 테스트 질문들\n",
    "test_questions = [\n",
    "    \"이 문서는 무엇에 대한 내용인가요?\",\n",
    "    \"문서에서 다루는 주요 주제는 무엇인가요?\",\n",
    "    \"PDF 문서 처리의 장점은 무엇인가요?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 이 문서는 무엇에 대한 내용인가요?\n",
      "답변: 이 문서는 IT 공급업체 관리, 특히 SSAE 16 평가와 ISO 인증과 같은 감사 및 품질 관리 프레임워크에 대한 내용입니다. 문서는 공급업체의 일반적인 통제 환경을 평가하는 SSAE 16, ISO 9001 및 ISO 27000 시리즈와 같은 표준에 대해 설명하고 있으며, 고객이 공급업체의 프로세스가 업계 모범 사례를 따르고 있음을 확인할 수 있도록 하는 방법에 대해 다루고 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "질문: 문서에서 다루는 주요 주제는 무엇인가요?\n",
      "답변: 주어진 문서에서 다루는 주요 주제는 IT 공급업체 관리와 관련된 감사 및 평가 절차입니다. 문서에서는 SSAE 16 평가, 감사 권리 조항, 그리고 외부 감사 기관의 역할에 대해 설명하고 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "질문: PDF 문서 처리의 장점은 무엇인가요?\n",
      "답변: 주어진 문서에서 해당 내용을 찾을 수 없습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. 테스트 실행\n",
    "for question in test_questions:\n",
    "    ask_document(chain, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.document_loaders import HWPLoader # HWP 로더 추가\n",
    "\n",
    "# HWP 파일 로드\n",
    "def load_hwp_document(file_path):\n",
    "    \"\"\"HWP 파일을 로드하고 기본 정보를 출력하는 함수\"\"\"\n",
    "    loader = HWPLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"문서 로드 완료: {len(documents)} 개의 문서\")\n",
    "    print(\"\\n문서 메타데이터:\", documents[0].metadata)\n",
    "    print(\"\\n문서 내용 샘플 (처음 300자):\", documents[0].page_content[:300])\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 로드 완료: 1 개의 문서\n",
      "\n",
      "문서 메타데이터: {'source': '테크노경영학환경분석.hwp'}\n",
      "\n",
      "문서 내용 샘플 (처음 300자): 외부환경분석-Study Buddy-테크노경영학정보 1팀김진아박현준배혜진송우정유현서조승민1. 거시환경분석 (PEST)ྠĀ1) 정치/법적 환경a. 저작권 및 지적 재산권 : 자료 공유 과정에서 저작권과 지적재산권에 대한 규제를 준수해야 하며, 공정 사용(fair use) 원칙을 숙지하여 자료 공유가 이루어질 수 있도록 모니터링이 필요함.  자료 공유 시 저작권과 지적재산권에 대한 규제를 준수해야 합니다. 교재나 요약 자료를 공유할 때에는 저작권법 저촉 여부를 신중히 검토하고 필요한 경우 저작물 사용에 대한 허가를 받아야 합니다. 특히 \n",
      "생성된 청크 수: 22\n",
      "\n",
      "질문: 온라인 학습 플랫폼 산업에 대해 설명해주세요.\n",
      "답변: 온라인 학습 플랫폼 산업은 IT 기술을 활용하여 교육 서비스를 제공하는 에듀테크 산업의 한 부분입니다. 이 산업은 디지털 경제의 확대로 인해 온라인 학습과 원격 교육에 대한 수요가 증가하면서 성장하고 있습니다. 특히, AI와 빅데이터를 기반으로 한 개인화 학습, 학습자 성향 분석, 맞춤형 학습 솔루션 제공 등을 통해 개별화된 교육이 가능해지고 있으며, 창의적 온라인 강의 개설, 네트워크 기반 그룹 학습, 학교 간 연계 학습 등을 통해 혁신적인 교육 방식의 구현이 가능해지고 있습니다.\n",
      "\n",
      "또한, 온라인 학습 플랫폼은 다양한 대체재의 존재와 플랫폼 간 자유로운 이동, 무료 체험판, 쉬운 구독 해지와 같은 낮은 전환 비용으로 인해 구매자의 협상력이 강화되는 경향이 있습니다. 그러나 AI 기반 개인화 학습, 실시간 피드백 시스템, 학습 데이터 분석 제공, 커뮤니티 기반 문제 공유와 같은 서비스 차별화와 다양한 가격 전략은 구매자의 협상력을 약화시키는 요인으로 작용합니다.\n",
      "\n",
      "이 산업은 특히 대학생과 같은 젊은 층이 비대면 학습과 자기주도 학습에 익숙해지면서 더욱 활성화되고 있으며, 모바일 기기를 통한 학습이 증가하는 추세에 맞춰 모바일 친화적인 콘텐츠와 인터페이스 개발의 중요성이 커지고 있습니다. 소비자들은 플랫폼 내에서 제공되는 자료의 신뢰성과 품질을 요구하며, 이에 따라 별점 평가 시스템과 신뢰도 높은 자료 우선 노출 기능 등을 통해 투명성을 높이고 사용자 신뢰를 구축하는 것이 중요합니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "documents = load_hwp_document(\"테크노경영학환경분석.hwp\")\n",
    "splits = split_documents(documents)\n",
    "chain = build_rag_system(splits)\n",
    "\n",
    "# 질의-응답 테스트\n",
    "ask_document(chain, \"온라인 학습 플랫폼 산업에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader  # DOCX 로더 추가\n",
    "\n",
    "# DOCX 파일 로드\n",
    "def load_docx_document(file_path):\n",
    "    \"\"\"DOCX 파일을 로드하고 기본 정보를 출력하는 함수\"\"\"\n",
    "    loader = Docx2txtLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"문서 로드 완료: {len(documents)} 개의 문서\")\n",
    "    print(\"\\n문서 메타데이터:\", documents[0].metadata)\n",
    "    print(\"\\n문서 내용 샘플 (처음 300자):\", documents[0].page_content[:300])\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 로드 완료: 1 개의 문서\n",
      "\n",
      "문서 메타데이터: {'source': '연구계획서.docx'}\n",
      "\n",
      "문서 내용 샘플 (처음 300자): Leveraging Large Language Models for Objective \n",
      "\n",
      "Analysis of Open-ended Psychological Responses\n",
      "\n",
      "연구 제목\n",
      "\n",
      "“대규모 언어 모델(LLM)을 활용한 주관식 심리 검사 응답의 객관화”\n",
      "\n",
      "연구의 배경 및 필요성\n",
      "\n",
      "심리 측정의 현대적 과제\n",
      "\n",
      "현대 심리학 연구에서 직면하고 있는 측정의 과제는 크게 세 가지 차원에서 검토될 수 있다. 첫째, 전통적인 객관식 측정 도구가 지닌 근본적 한계이다. Schwartz 등(2001)이 지적한 바와 같이, 리커트 척도로 대표되는 \n",
      "생성된 청크 수: 10\n",
      "\n",
      "질문: 연구계획서에 대해 설명해주세요.\n",
      "답변: 연구계획서는 대규모 언어 모델(LLM)을 활용하여 주관식 심리 검사 응답을 객관적이고 효율적으로 분석할 수 있는 새로운 방법론을 개발하고 검증하는 것을 목표로 하고 있습니다. 이를 위해 LLM 기반의 심리 검사 응답 분석 시스템을 개발하고, 프롬프트 엔지니어링과 결과 해석 프레임워크를 구축하여 신뢰도와 타당도를 검증할 계획입니다. 연구는 LLM의 few-shot learning 성능과 분석 과정의 설명가능성을 평가하며, 다단계 실험 설계를 통해 LLM의 효과성을 검증합니다. 데이터 수집은 표준화된 심리 검사와 주관식 응답을 통해 이루어지며, 분석은 LLM의 결과와 객관식 검사 점수 간의 상관관계, 신뢰도, 질적 평가를 포함합니다. 윤리적 고려사항으로는 개인정보 보호와 데이터 보안이 강조됩니다. 연구는 LLM 기반 심리 검사 분석의 타당성과 실용성을 검증하고, 새로운 심리 검사 패러다임의 가능성을 탐색하고자 합니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "documents = load_docx_document(\"연구계획서.docx\")\n",
    "splits = split_documents(documents)\n",
    "chain = build_rag_system(splits)\n",
    "\n",
    "# 질의-응답 테스트\n",
    "ask_document(chain, \"연구계획서에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arxiv_papers(query, max_docs=2):\n",
    "    \"\"\"arXiv 논문을 검색하고 로드하는 함수\"\"\"\n",
    "    try:\n",
    "        # ArxivLoader 설정 \n",
    "        # PDFMiner 사용을 위해 doc_content_chars_max를 설정\n",
    "        loader = ArxivLoader(\n",
    "            query=query,\n",
    "            load_max_docs=max_docs,\n",
    "            load_all_available_meta=True,\n",
    "            doc_content_chars_max=None,  # 전체 문서 로드\n",
    "            pdf_loader_kwargs={'pdf_loader_cls_name': 'PDFMinerLoader'}  # PDFMiner 사용\n",
    "        )\n",
    "        \n",
    "        # 문서 로드\n",
    "        docs = loader.load()\n",
    "        \n",
    "        print(f\"검색된 논문 수: {len(docs)}\")\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            print(f\"\\n논문 {i} 정보:\")\n",
    "            print(f\"제목: {doc.metadata.get('Title')}\")\n",
    "            print(f\"저자: {doc.metadata.get('Authors')}\")\n",
    "            print(f\"출판일: {doc.metadata.get('Published')}\")\n",
    "            print(f\"요약: {doc.metadata.get('Summary')[:200]}...\")\n",
    "            \n",
    "        return docs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"논문 로드 중 오류 발생: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 논문 수: 2\n",
      "\n",
      "논문 1 정보:\n",
      "제목: Lecture Notes: Optimization for Machine Learning\n",
      "저자: Elad Hazan\n",
      "출판일: 2019-09-08\n",
      "요약: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as well as\n",
      "Simons Foundation, Berkeley....\n",
      "\n",
      "논문 2 정보:\n",
      "제목: An Optimal Control View of Adversarial Machine Learning\n",
      "저자: Xiaojin Zhu\n",
      "출판일: 2018-11-11\n",
      "요약: I describe an optimal control view of adversarial machine learning, where the\n",
      "dynamical system is the machine learner, the input are adversarial actions, and\n",
      "the control costs are defined by the adver...\n",
      "생성된 청크 수: 228\n",
      "\n",
      "질문: 머신러닝에 대해 설명해주세요.\n",
      "답변: 주어진 문서에서 머신러닝에 대한 설명은 다음과 같습니다. 머신러닝은 기계가 원하는 기능을 달성하도록 훈련(교육)하는 과정입니다. 이는 알고리즘적 작업을 해결할 수 있는 기계를 자동화된 메커니즘으로 학습시키는 것을 의미합니다. 기계는 작업에 따라 다르며, 기계의 기능을 결정하는 매개변수 세트에 의해 구별됩니다. 이러한 접근 방식은 컴퓨터 칩의 배선이 기능을 결정하는 것과 유사합니다. 특히, 인공 신경망이 가장 인기 있는 기계 중 하나입니다. 머신러닝의 수학적 최적화 접근법은 기계 훈련 과정을 최적화 문제로 보는 것입니다. 매개변수 w가 특정 집합 K에 제한되고, f가 예제를 올바른 레이블로 매핑하는 성공을 측정하는 함수일 때, 관심 있는 문제는 이러한 매개변수를 최적화하는 것입니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "documents = load_arxiv_papers(\"machine learning\", 2)\n",
    "splits = split_documents(documents)\n",
    "chain = build_rag_system(splits)\n",
    "\n",
    "# 질의-응답 테스트\n",
    "ask_document(chain, \"머신러닝에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
